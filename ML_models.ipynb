{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import glob2 as glob\n",
    "\n",
    "import copy\n",
    "#import config\n",
    "#import dota2api\n",
    "import json\n",
    "import requests\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import seaborn as sns\n",
    "#import plotly.express as px\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, filename='logit_model'):\n",
    "    df_submission = pd.DataFrame({'radiant_win_prob': predicted_labels}, \n",
    "                                     index=test_features.index)\n",
    "\n",
    "    submission_filename = '{}_{}.csv'.format(filename,\n",
    "        datetime.datetime.now(tz=pytz.timezone('US/Pacific')).strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    \n",
    "    df_submission.to_csv(submission_filename)\n",
    "    \n",
    "    print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Hero Lookup \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@waprin/python-and-dota2-analyzing-team-liquids-io-success-and-failure-7d44cc5979b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hero names and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 20607    0 20607    0     0  93244      0 --:--:-- --:--:-- --:--:-- 93244\n"
     ]
    }
   ],
   "source": [
    "!curl https://api.opendota.com/api/heroes > heroes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_dict = {}\n",
    "with open('heroes.json') as f:\n",
    "    data = json.load(f)\n",
    "    for h in data:\n",
    "        hero_dict[h['id']] = h['localized_name']\n",
    "#print(hero_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEAM Client API Key to access the dota2 api\n",
    "#API_KEY = config.(96E9FAA2D511E90BFE0F1CE229834E0C)\n",
    "#api = dota2api.Initialise(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1hero_id', '2hero_id', '3hero_id', '4hero_id', '5hero_id', '6hero_id', '7hero_id', '8hero_id', '9hero_id', '10hero_id', '11hero_id', '12hero_id', '13hero_id', '14hero_id', '15hero_id', '16hero_id', '17hero_id', '18hero_id', '19hero_id', '20hero_id', '21hero_id', '22hero_id']\n"
     ]
    }
   ],
   "source": [
    "# Cleaner way to create columns for re-naming \n",
    "\n",
    "col2 = [f'{i}hero_id' for i in range(1, 23)]\n",
    "print(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_full_features1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8ea2847c6dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m    \u001b[0mdf_full_features1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_full_features1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange_hero_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_full_features1' is not defined"
     ]
    }
   ],
   "source": [
    "# Run this once match data loaded in \n",
    "\n",
    "# https://github.com/codexponent/dota2-draft-analysis/blob/master/README.md\n",
    "\n",
    "def change_hero_name(row):\n",
    "    if row in hero_dict:\n",
    "        return hero_dict[row]\n",
    "    \n",
    "columns = [\n",
    "    '1hero_id',\n",
    "    '2hero_id',\n",
    "    '3hero_id',\n",
    "    '4hero_id',\n",
    "    '5hero_id',\n",
    "    '6hero_id',\n",
    "    '7hero_id',\n",
    "    '8hero_id',\n",
    "    '9hero_id',\n",
    "    '10hero_id',\n",
    "    '11hero_id',\n",
    "    '12hero_id',\n",
    "    '13hero_id',\n",
    "    '14hero_id',\n",
    "    '15hero_id',\n",
    "    '16hero_id',\n",
    "    '17hero_id',\n",
    "    '18hero_id',\n",
    "    '19hero_id',\n",
    "    '20hero_id',\n",
    "    '21hero_id',\n",
    "    '22hero_id'\n",
    "]\n",
    "    \n",
    "for i in range(len(columns)):\n",
    "   df_full_features1[columns[i]] = df_full_features1[columns[i]].apply(change_hero_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhero_train = df_full_features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rhero_train.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_df = df_full_features[[f'{i}hero_id' for i in range(1, 23)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing logistic regression with just hot encoded heroes and see what results are like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Training and Test Data  \n",
    "train_features = pd.read_csv('data2/dpc_train_features.csv', index_col='match_id')\n",
    "train_targets = pd.read_csv('data2/dpc_train_target.csv', index_col='match_id')\n",
    "test_features = pd.read_csv('data2/dpc_test_features.csv', index_col='match_id')\n",
    "test_targets = pd.read_csv('data2/dpc_test_target.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 66), (1045, 2), (117, 66), (117, 2))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_targets.shape, test_features.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_full_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-47af82dfdc63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0midx_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mheroes_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_full_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{i}hero_id'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_full_features' is not defined"
     ]
    }
   ],
   "source": [
    "merge_features_df = pd.concat([train_features, test_features])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_features.shape[0]\n",
    "\n",
    "heroes_df = df_full_features[[f'{i}hero_id' for i in range(1, 23)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_features1 = df_full_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_df1 = heroes_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1162, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check that hero ids are unique (i.e., no double picking)\n",
    "# https://www.kaggle.com/kuzand/dota-2-winner-prediction-multilayer-nn-pytorch\n",
    "\n",
    "np.all(df_full_features[[f'{i}hero_id' for i in range(1, 23)]].nunique(axis=1) == 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(np.unique(heroes_df[[f'{i}hero_id' for i in range(1, 23)]].values.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(heroes_df[[f'{i}hero_id' for i in range(1, 23)]],return_counts=True) \n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_df_ohe = heroes_df.copy()\n",
    "for i in range(1, 23):\n",
    "    heroes_df_ohe = pd.get_dummies(heroes_df_ohe, columns = [f'{i}hero_id'])\n",
    "        \n",
    "heroes_df_ohe.head()\n",
    "\n",
    "X_heroes_train = heroes_df_ohe[:idx_split] # features set is only picks + dummies\n",
    "X_heroes_test  = heroes_df_ohe[idx_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 2044\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of features: {heroes_df_ohe.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 2044), (117, 2044))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_heroes_train.shape, X_heroes_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1hero_id_2</th>\n",
       "      <th>1hero_id_3</th>\n",
       "      <th>1hero_id_4</th>\n",
       "      <th>1hero_id_6</th>\n",
       "      <th>1hero_id_7</th>\n",
       "      <th>1hero_id_9</th>\n",
       "      <th>1hero_id_10</th>\n",
       "      <th>1hero_id_16</th>\n",
       "      <th>1hero_id_18</th>\n",
       "      <th>1hero_id_19</th>\n",
       "      <th>1hero_id_23</th>\n",
       "      <th>1hero_id_25</th>\n",
       "      <th>1hero_id_27</th>\n",
       "      <th>1hero_id_29</th>\n",
       "      <th>1hero_id_31</th>\n",
       "      <th>1hero_id_33</th>\n",
       "      <th>1hero_id_37</th>\n",
       "      <th>1hero_id_38</th>\n",
       "      <th>1hero_id_40</th>\n",
       "      <th>1hero_id_41</th>\n",
       "      <th>1hero_id_42</th>\n",
       "      <th>1hero_id_43</th>\n",
       "      <th>1hero_id_46</th>\n",
       "      <th>1hero_id_52</th>\n",
       "      <th>1hero_id_53</th>\n",
       "      <th>1hero_id_55</th>\n",
       "      <th>1hero_id_57</th>\n",
       "      <th>1hero_id_58</th>\n",
       "      <th>1hero_id_59</th>\n",
       "      <th>1hero_id_60</th>\n",
       "      <th>1hero_id_61</th>\n",
       "      <th>1hero_id_62</th>\n",
       "      <th>1hero_id_65</th>\n",
       "      <th>1hero_id_66</th>\n",
       "      <th>1hero_id_68</th>\n",
       "      <th>1hero_id_69</th>\n",
       "      <th>1hero_id_71</th>\n",
       "      <th>1hero_id_72</th>\n",
       "      <th>1hero_id_73</th>\n",
       "      <th>1hero_id_74</th>\n",
       "      <th>1hero_id_75</th>\n",
       "      <th>1hero_id_76</th>\n",
       "      <th>1hero_id_79</th>\n",
       "      <th>1hero_id_80</th>\n",
       "      <th>1hero_id_81</th>\n",
       "      <th>1hero_id_82</th>\n",
       "      <th>1hero_id_83</th>\n",
       "      <th>1hero_id_84</th>\n",
       "      <th>1hero_id_85</th>\n",
       "      <th>1hero_id_86</th>\n",
       "      <th>1hero_id_87</th>\n",
       "      <th>1hero_id_88</th>\n",
       "      <th>1hero_id_89</th>\n",
       "      <th>1hero_id_90</th>\n",
       "      <th>1hero_id_91</th>\n",
       "      <th>1hero_id_93</th>\n",
       "      <th>1hero_id_96</th>\n",
       "      <th>1hero_id_97</th>\n",
       "      <th>1hero_id_98</th>\n",
       "      <th>1hero_id_99</th>\n",
       "      <th>1hero_id_102</th>\n",
       "      <th>1hero_id_103</th>\n",
       "      <th>1hero_id_104</th>\n",
       "      <th>1hero_id_105</th>\n",
       "      <th>1hero_id_106</th>\n",
       "      <th>1hero_id_107</th>\n",
       "      <th>1hero_id_111</th>\n",
       "      <th>1hero_id_112</th>\n",
       "      <th>1hero_id_119</th>\n",
       "      <th>1hero_id_120</th>\n",
       "      <th>1hero_id_121</th>\n",
       "      <th>1hero_id_129</th>\n",
       "      <th>2hero_id_2</th>\n",
       "      <th>2hero_id_3</th>\n",
       "      <th>2hero_id_4</th>\n",
       "      <th>2hero_id_7</th>\n",
       "      <th>2hero_id_9</th>\n",
       "      <th>2hero_id_10</th>\n",
       "      <th>2hero_id_16</th>\n",
       "      <th>2hero_id_17</th>\n",
       "      <th>2hero_id_18</th>\n",
       "      <th>2hero_id_19</th>\n",
       "      <th>2hero_id_22</th>\n",
       "      <th>2hero_id_23</th>\n",
       "      <th>2hero_id_25</th>\n",
       "      <th>2hero_id_29</th>\n",
       "      <th>2hero_id_31</th>\n",
       "      <th>2hero_id_33</th>\n",
       "      <th>2hero_id_37</th>\n",
       "      <th>2hero_id_38</th>\n",
       "      <th>2hero_id_41</th>\n",
       "      <th>2hero_id_42</th>\n",
       "      <th>2hero_id_43</th>\n",
       "      <th>2hero_id_46</th>\n",
       "      <th>2hero_id_50</th>\n",
       "      <th>2hero_id_52</th>\n",
       "      <th>2hero_id_53</th>\n",
       "      <th>2hero_id_54</th>\n",
       "      <th>2hero_id_55</th>\n",
       "      <th>2hero_id_57</th>\n",
       "      <th>...</th>\n",
       "      <th>22hero_id_1</th>\n",
       "      <th>22hero_id_2</th>\n",
       "      <th>22hero_id_4</th>\n",
       "      <th>22hero_id_5</th>\n",
       "      <th>22hero_id_6</th>\n",
       "      <th>22hero_id_7</th>\n",
       "      <th>22hero_id_8</th>\n",
       "      <th>22hero_id_10</th>\n",
       "      <th>22hero_id_11</th>\n",
       "      <th>22hero_id_12</th>\n",
       "      <th>22hero_id_13</th>\n",
       "      <th>22hero_id_14</th>\n",
       "      <th>22hero_id_15</th>\n",
       "      <th>22hero_id_16</th>\n",
       "      <th>22hero_id_17</th>\n",
       "      <th>22hero_id_18</th>\n",
       "      <th>22hero_id_19</th>\n",
       "      <th>22hero_id_21</th>\n",
       "      <th>22hero_id_22</th>\n",
       "      <th>22hero_id_23</th>\n",
       "      <th>22hero_id_25</th>\n",
       "      <th>22hero_id_26</th>\n",
       "      <th>22hero_id_27</th>\n",
       "      <th>22hero_id_28</th>\n",
       "      <th>22hero_id_29</th>\n",
       "      <th>22hero_id_32</th>\n",
       "      <th>22hero_id_33</th>\n",
       "      <th>22hero_id_34</th>\n",
       "      <th>22hero_id_35</th>\n",
       "      <th>22hero_id_36</th>\n",
       "      <th>22hero_id_37</th>\n",
       "      <th>22hero_id_38</th>\n",
       "      <th>22hero_id_39</th>\n",
       "      <th>22hero_id_40</th>\n",
       "      <th>22hero_id_41</th>\n",
       "      <th>22hero_id_42</th>\n",
       "      <th>22hero_id_43</th>\n",
       "      <th>22hero_id_44</th>\n",
       "      <th>22hero_id_45</th>\n",
       "      <th>22hero_id_46</th>\n",
       "      <th>22hero_id_47</th>\n",
       "      <th>22hero_id_48</th>\n",
       "      <th>22hero_id_49</th>\n",
       "      <th>22hero_id_50</th>\n",
       "      <th>22hero_id_51</th>\n",
       "      <th>22hero_id_52</th>\n",
       "      <th>22hero_id_53</th>\n",
       "      <th>22hero_id_54</th>\n",
       "      <th>22hero_id_55</th>\n",
       "      <th>22hero_id_56</th>\n",
       "      <th>22hero_id_57</th>\n",
       "      <th>22hero_id_58</th>\n",
       "      <th>22hero_id_59</th>\n",
       "      <th>22hero_id_60</th>\n",
       "      <th>22hero_id_61</th>\n",
       "      <th>22hero_id_62</th>\n",
       "      <th>22hero_id_63</th>\n",
       "      <th>22hero_id_65</th>\n",
       "      <th>22hero_id_67</th>\n",
       "      <th>22hero_id_68</th>\n",
       "      <th>22hero_id_70</th>\n",
       "      <th>22hero_id_71</th>\n",
       "      <th>22hero_id_72</th>\n",
       "      <th>22hero_id_73</th>\n",
       "      <th>22hero_id_74</th>\n",
       "      <th>22hero_id_75</th>\n",
       "      <th>22hero_id_76</th>\n",
       "      <th>22hero_id_77</th>\n",
       "      <th>22hero_id_78</th>\n",
       "      <th>22hero_id_79</th>\n",
       "      <th>22hero_id_80</th>\n",
       "      <th>22hero_id_81</th>\n",
       "      <th>22hero_id_82</th>\n",
       "      <th>22hero_id_84</th>\n",
       "      <th>22hero_id_85</th>\n",
       "      <th>22hero_id_86</th>\n",
       "      <th>22hero_id_88</th>\n",
       "      <th>22hero_id_89</th>\n",
       "      <th>22hero_id_92</th>\n",
       "      <th>22hero_id_93</th>\n",
       "      <th>22hero_id_94</th>\n",
       "      <th>22hero_id_95</th>\n",
       "      <th>22hero_id_96</th>\n",
       "      <th>22hero_id_97</th>\n",
       "      <th>22hero_id_98</th>\n",
       "      <th>22hero_id_99</th>\n",
       "      <th>22hero_id_101</th>\n",
       "      <th>22hero_id_102</th>\n",
       "      <th>22hero_id_104</th>\n",
       "      <th>22hero_id_106</th>\n",
       "      <th>22hero_id_107</th>\n",
       "      <th>22hero_id_108</th>\n",
       "      <th>22hero_id_109</th>\n",
       "      <th>22hero_id_110</th>\n",
       "      <th>22hero_id_112</th>\n",
       "      <th>22hero_id_113</th>\n",
       "      <th>22hero_id_114</th>\n",
       "      <th>22hero_id_120</th>\n",
       "      <th>22hero_id_121</th>\n",
       "      <th>22hero_id_129</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5115031896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865407245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889341660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050335216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860032461</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2044 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1hero_id_2  1hero_id_3  1hero_id_4  1hero_id_6  1hero_id_7  \\\n",
       "match_id                                                                 \n",
       "5115031896           0           0           0           0           0   \n",
       "4865407245           0           0           0           0           0   \n",
       "4889341660           0           0           0           0           0   \n",
       "5050335216           0           0           0           0           0   \n",
       "4860032461           0           0           0           0           0   \n",
       "\n",
       "            1hero_id_9  1hero_id_10  1hero_id_16  1hero_id_18  1hero_id_19  \\\n",
       "match_id                                                                     \n",
       "5115031896           0            0            0            0            0   \n",
       "4865407245           0            0            0            0            0   \n",
       "4889341660           0            0            0            0            0   \n",
       "5050335216           0            0            0            0            0   \n",
       "4860032461           0            0            0            0            0   \n",
       "\n",
       "            1hero_id_23  1hero_id_25  1hero_id_27  1hero_id_29  1hero_id_31  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            1            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_33  1hero_id_37  1hero_id_38  1hero_id_40  1hero_id_41  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_42  1hero_id_43  1hero_id_46  1hero_id_52  1hero_id_53  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_55  1hero_id_57  1hero_id_58  1hero_id_59  1hero_id_60  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_61  1hero_id_62  1hero_id_65  1hero_id_66  1hero_id_68  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_69  1hero_id_71  1hero_id_72  1hero_id_73  1hero_id_74  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            1            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_75  1hero_id_76  1hero_id_79  1hero_id_80  1hero_id_81  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_82  1hero_id_83  1hero_id_84  1hero_id_85  1hero_id_86  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            1            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_87  1hero_id_88  1hero_id_89  1hero_id_90  1hero_id_91  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_93  1hero_id_96  1hero_id_97  1hero_id_98  1hero_id_99  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            1hero_id_102  1hero_id_103  1hero_id_104  1hero_id_105  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             1   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            1hero_id_106  1hero_id_107  1hero_id_111  1hero_id_112  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             1             0   \n",
       "\n",
       "            1hero_id_119  1hero_id_120  1hero_id_121  1hero_id_129  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            2hero_id_2  2hero_id_3  2hero_id_4  2hero_id_7  2hero_id_9  \\\n",
       "match_id                                                                 \n",
       "5115031896           0           0           0           0           0   \n",
       "4865407245           0           0           0           0           0   \n",
       "4889341660           0           0           0           0           0   \n",
       "5050335216           0           0           0           0           0   \n",
       "4860032461           0           0           0           0           0   \n",
       "\n",
       "            2hero_id_10  2hero_id_16  2hero_id_17  2hero_id_18  2hero_id_19  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            1            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            1            0   \n",
       "\n",
       "            2hero_id_22  2hero_id_23  2hero_id_25  2hero_id_29  2hero_id_31  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            2hero_id_33  2hero_id_37  2hero_id_38  2hero_id_41  2hero_id_42  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            2hero_id_43  2hero_id_46  2hero_id_50  2hero_id_52  2hero_id_53  \\\n",
       "match_id                                                                      \n",
       "5115031896            0            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            2hero_id_54  2hero_id_55  2hero_id_57  ...  22hero_id_1  \\\n",
       "match_id                                           ...                \n",
       "5115031896            0            0            0  ...            0   \n",
       "4865407245            0            0            0  ...            0   \n",
       "4889341660            0            0            0  ...            0   \n",
       "5050335216            0            0            0  ...            0   \n",
       "4860032461            0            0            0  ...            0   \n",
       "\n",
       "            22hero_id_2  22hero_id_4  22hero_id_5  22hero_id_6  22hero_id_7  \\\n",
       "match_id                                                                      \n",
       "5115031896            1            0            0            0            0   \n",
       "4865407245            0            0            0            0            0   \n",
       "4889341660            0            0            0            0            0   \n",
       "5050335216            0            0            0            0            0   \n",
       "4860032461            0            0            0            0            0   \n",
       "\n",
       "            22hero_id_8  22hero_id_10  22hero_id_11  22hero_id_12  \\\n",
       "match_id                                                            \n",
       "5115031896            0             0             0             0   \n",
       "4865407245            0             0             0             0   \n",
       "4889341660            0             0             0             0   \n",
       "5050335216            0             0             0             0   \n",
       "4860032461            0             0             0             0   \n",
       "\n",
       "            22hero_id_13  22hero_id_14  22hero_id_15  22hero_id_16  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_17  22hero_id_18  22hero_id_19  22hero_id_21  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_22  22hero_id_23  22hero_id_25  22hero_id_26  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_27  22hero_id_28  22hero_id_29  22hero_id_32  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_33  22hero_id_34  22hero_id_35  22hero_id_36  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_37  22hero_id_38  22hero_id_39  22hero_id_40  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_41  22hero_id_42  22hero_id_43  22hero_id_44  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             1             0             0   \n",
       "4889341660             0             0             1             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_45  22hero_id_46  22hero_id_47  22hero_id_48  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_49  22hero_id_50  22hero_id_51  22hero_id_52  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_53  22hero_id_54  22hero_id_55  22hero_id_56  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_57  22hero_id_58  22hero_id_59  22hero_id_60  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             1             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_61  22hero_id_62  22hero_id_63  22hero_id_65  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_67  22hero_id_68  22hero_id_70  22hero_id_71  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_72  22hero_id_73  22hero_id_74  22hero_id_75  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             1             0             0   \n",
       "\n",
       "            22hero_id_76  22hero_id_77  22hero_id_78  22hero_id_79  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_80  22hero_id_81  22hero_id_82  22hero_id_84  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_85  22hero_id_86  22hero_id_88  22hero_id_89  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_92  22hero_id_93  22hero_id_94  22hero_id_95  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_96  22hero_id_97  22hero_id_98  22hero_id_99  \\\n",
       "match_id                                                             \n",
       "5115031896             0             0             0             0   \n",
       "4865407245             0             0             0             0   \n",
       "4889341660             0             0             0             0   \n",
       "5050335216             0             0             0             0   \n",
       "4860032461             0             0             0             0   \n",
       "\n",
       "            22hero_id_101  22hero_id_102  22hero_id_104  22hero_id_106  \\\n",
       "match_id                                                                 \n",
       "5115031896              0              0              0              0   \n",
       "4865407245              0              0              0              0   \n",
       "4889341660              0              0              0              0   \n",
       "5050335216              0              0              0              0   \n",
       "4860032461              0              0              0              0   \n",
       "\n",
       "            22hero_id_107  22hero_id_108  22hero_id_109  22hero_id_110  \\\n",
       "match_id                                                                 \n",
       "5115031896              0              0              0              0   \n",
       "4865407245              0              0              0              0   \n",
       "4889341660              0              0              0              0   \n",
       "5050335216              0              0              0              0   \n",
       "4860032461              0              0              0              0   \n",
       "\n",
       "            22hero_id_112  22hero_id_113  22hero_id_114  22hero_id_120  \\\n",
       "match_id                                                                 \n",
       "5115031896              0              0              0              0   \n",
       "4865407245              0              0              0              0   \n",
       "4889341660              0              0              0              0   \n",
       "5050335216              0              0              0              0   \n",
       "4860032461              0              0              0              0   \n",
       "\n",
       "            22hero_id_121  22hero_id_129  \n",
       "match_id                                  \n",
       "5115031896              0              0  \n",
       "4865407245              0              0  \n",
       "4889341660              0              0  \n",
       "5050335216              0              0  \n",
       "4860032461              0              0  \n",
       "\n",
       "[5 rows x 2044 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_heroes_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot encoding by getting dummies for each hero_id feature.\n",
    "\n",
    "*Note: Not every 117 heroes were chosen for each pick (1-22). Therefore, columns will be less than 22 x 117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([train_features, test_features])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 2088)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,23):\n",
    "        all_features = pd.get_dummies(all_features, columns = [f'{i}hero_id'])\n",
    "\n",
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling \n",
    "\n",
    "Trying it out with minmax. From what I can tell, this seems like the most appropriate scaling method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_features_scaled = df_full_features.copy()\n",
    "df_full_features_scaled[df_full_features.columns.tolist()] = MinMaxScaler().fit_transform(df_full_features_scaled[df_full_features.columns.tolist()])  # alternatively use StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_features_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_features_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like we have the entire data set hot encoded and scaled (minmax). Time to split it back up and go forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Set targets, features, and verification set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should the combined train sets still have hero variables? did I do this right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoded train/test features\n",
    "# Try this once without scaling \n",
    "\n",
    "X_train = all_features[:idx_split]\n",
    "X_test = all_features[idx_split:]\n",
    "\n",
    "y_train = train_targets.radiant_win\n",
    "y_test = test_targets.radiant_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remainder = all_features[:idx_split]\n",
    "X_test = all_features[idx_split:]\n",
    "\n",
    "y_remainder = train_targets.radiant_win.values\n",
    "y_test = test_targets.radiant_win.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep full version of training set to use for final accuracy model \n",
    "X_train_full = X_train.copy() \n",
    "y_train_full = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 2088), (1045,), (1045,), (105,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_features_ohe = X_train_full\n",
    "test_features_ohe = y_train_full\n",
    "train_features_ohe.shape, test_features_ohe.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 2088), (1045, 2088), (117, 2088), (1045,), (1045,), (117,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure everything is correct size\n",
    "X_train.shape, X_train_full.shape, X_test.shape, y_train.shape, y_train_full.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems in order, let's do our validation split and get into the modelliing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Split\n",
    "\n",
    "Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1, random_state = SEED) ## see top, SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((940, 2088), (105, 2088), (940,), (105,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set: (117, 2088)\n",
      "Shape of validation set: (105, 2088)\n",
      "Shape of train set: (940, 2088)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of test set: {X_test.shape}')\n",
    "print(f'Shape of validation set: {X_valid.shape}')\n",
    "print(f'Shape of train set: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logit Model 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression 1. \n",
    "\n",
    "Let's see what the out of the box results are like. Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1 = LogisticRegression(random_state=random_state, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train Set: 0.9968085106382979\n",
      "Accuracy Score on validation Set: 0.4666666666666667\n",
      "Logit model validation roc_auc score: 0.4660740203193033\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit1.fit(X_train, y_train)\n",
    "y_pred = logit1.predict(X_valid)\n",
    "y_pred_proba = logit1.predict_proba(X_valid)\n",
    "\n",
    "print(f\"Accuracy Score on Train Set: {logit1.score(X_train, y_train)}\")\n",
    "print(f\"Accuracy Score on validation Set: {logit1.score(X_valid, y_valid)}\")\n",
    "print(f'Logit model validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's compare out of the box results after scaling the data. Scaling data after the two splits to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train1, X_valid1, X_test1 = X_train.copy(), X_valid.copy(), X_test.copy()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train1)\n",
    "X_valid_scaled = scaler.fit_transform(X_valid1)\n",
    "X_test_scaled = scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2 = LogisticRegression(random_state=random_state, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train Set: 0.9968085106382979\n",
      "Accuracy Score on validation Set: 0.4666666666666667\n",
      "Log Regression validation roc_auc score: 0.4660740203193033\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit2.fit(X_train_scaled, y_train)\n",
    "y_pred = logit1.predict(X_valid)\n",
    "y_pred_proba = logit2.predict_proba(X_valid_scaled)\n",
    "\n",
    "print(f\"Accuracy Score on Train Set: {logit2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Accuracy Score on validation Set: {logit2.score(X_valid_scaled, y_valid)}\")\n",
    "\n",
    "print(f'Log Regression validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow what a surprise, since all my features return values of 0 or 1, scaling doesn't do anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "logreg = LogisticRegression(random_state=17)\n",
    "forest = RandomForestClassifier(random_state=17)\n",
    "bayes = MultinomialNB()\n",
    "xg = XGBClassifier(random_state=17)\n",
    "cat = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_remainder_scaled = MinMaxScaler().fit_transform(X_train1)\n",
    "#X_valid_scale = MinMaxScaler().fit_transform(X_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [logreg, forest, xg, bayes]\n",
    "acc_train = []\n",
    "acc_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = ShuffleSplit(n_splits=5, random_state=SEED) #using a shuffle split for CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#THIS CELL TAKES A WHILE TO RUN\n",
    "for i in classifiers:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_remainder, y_remainder, test_size=0.1, random_state=17)\n",
    "\n",
    "    scores = cross_val_score(i, X_train, y_train, cv=5)\n",
    "    acc_train.append(np.mean(scores))\n",
    "    \n",
    "    model = i.fit(X_train, y_train)\n",
    "    #y_pred_valid = i.predict(X_valid)\n",
    "    acc_test.append(model.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.490426</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(DecisionTreeClassifier(ccp_alpha=0.0, class_w...</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster=None, co...</td>\n",
       "      <td>0.482979</td>\n",
       "      <td>0.419048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.523404</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              models  Training Accuracy  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...           0.490426   \n",
       "1  (DecisionTreeClassifier(ccp_alpha=0.0, class_w...           0.484043   \n",
       "2  XGBClassifier(base_score=0.5, booster=None, co...           0.482979   \n",
       "3  MultinomialNB(alpha=1.0, class_prior=None, fit...           0.523404   \n",
       "\n",
       "   Validation Accuracy  \n",
       "0             0.466667  \n",
       "1             0.380952  \n",
       "2             0.419048  \n",
       "3             0.466667  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_base = pd.DataFrame({'models': classifiers,\n",
    "              'Training Accuracy': acc_train,\n",
    "              'Validation Accuracy': acc_test})\n",
    "summary_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'C':[.00000001,.0000001,.000001,.00001,.0001,.001,.01, .1,\\\n",
    "                          1,10,100,1000,10000,100000,1000000,10000000,100000000,1000000000],\n",
    "                     'penalty': ['l1', 'l2']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://www.kaggle.com/smsrikanthreddy/dota-2-win-prediction-logistic-regression\n",
    "\n",
    "#calcuate ROC-AUC for each split\n",
    "#logistic Regression\n",
    "C = 1\n",
    "penalty = 'l2'\n",
    "max_iter = 100\n",
    "solver = 'lbfgs'\n",
    "random_state = SEED\n",
    "n_jobs = -1\n",
    "verbose = 0\n",
    "\n",
    "logit1 = LogisticRegression(C=C,\n",
    "                            penalty=penalty,\n",
    "                            max_iter=max_iter, \n",
    "                            random_state=random_state,\n",
    "                            verbose=verbose,\n",
    "                            n_jobs=n_jobs,\n",
    "                           solver=solver)\n",
    "\n",
    "#cv_scores_lr1 = cross_val_score(clf_lr_1, X_train, y, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train Set: 0.9968085106382979\n",
      "Accuracy Score on validation Set: 0.4666666666666667\n",
      "Logit model validation roc_auc score: 0.4660740203193033\n",
      "Wall time: 3.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit1.fit(X_train, y_train)\n",
    "y_pred = logit1.predict(X_valid)\n",
    "y_pred_proba = logit1.predict_proba(X_valid)\n",
    "\n",
    "print(f\"Accuracy Score on Train Set: {logit1.score(X_train, y_train)}\")\n",
    "print(f\"Accuracy Score on validation Set: {logit1.score(X_valid, y_valid)}\")\n",
    "\n",
    "print(f'Logit model validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Predict Probability on Train Set: {logit1.predict_proba(X_train)}\")\n",
    "#print(f\"Predict Probability on Train Set: {logit1.predict_proba(X_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well those don't look too good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit1.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "validation_scores = []\n",
    "train_scores = []\n",
    "\n",
    "C_range = np.array([.00000001,.0000001,.000001,.00001,.0001,.001,0.1,\\\n",
    "                1,10,100,1000,10000,100000,1000000,10000000,100000000,1000000000])\n",
    "\n",
    "for c in C_range:\n",
    "    logit = LogisticRegression(C = c,random_state=SEED)\n",
    "    logit.fit(X_train,y_train)\n",
    "    \n",
    "    # train on traning set\n",
    "    train_scores.append(logit.score(X_train,y_train))\n",
    "    # score on validation set\n",
    "    validation_scores.append(logit.score(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(C_range, train_scores,label=\"Train Scores\",marker='.')\n",
    "plt.plot(C_range, validation_scores,label=\"Validation Scores\",marker='.')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('Regularization Parameter: C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has C =  0.001\n",
      "CPU times: user 27.5 s, sys: 457 ms, total: 27.9 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Store the results\n",
    "cross_validation_scores = []\n",
    "\n",
    "C_range = np.array([.00000001,.0000001,.000001,.00001,.0001,.001,.1,\\\n",
    "                1,10,100,1000,10000,100000,1000000,10000000,100000000,1000000000])\n",
    "\n",
    "#Do some cross validation\n",
    "for c in C_range:\n",
    "    logit = LogisticRegression(C=c,random_state=SEED, solver = 'lbfgs')\n",
    "    \n",
    "    #the cross validation score (mean of scores from all folds)\n",
    "    cv_score = np.mean(cross_val_score(logit, X_train, y_train, cv = 5))\n",
    "    \n",
    "    cross_validation_scores.append(cv_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_range, cross_validation_scores,label=\"Cross Validation Score\",marker='.')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('Regularization Parameter: C')\n",
    "plt.ylabel('Cross Validation Score')\n",
    "plt.grid()\n",
    "plt.show();\n",
    "\n",
    "which_max = np.array(cross_validation_scores).argmax()\n",
    "\n",
    "print(\"The best model has C = \",C_range[which_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.5042553492490913\n",
      "Fold 2: 0.5042553492490913\n",
      "Fold 3: 0.5042553492490913\n",
      "Fold 4: 0.5042553492490913\n",
      "Fold 5: 0.5042553492490913\n",
      "Fold 6: 0.5276939789455434\n",
      "Fold 7: 0.49156861541091834\n",
      "Fold 8: 0.4830012684205425\n",
      "Fold 9: 0.48404809162005663\n",
      "Fold 10: 0.48405372034908956\n",
      "Fold 11: 0.4808904348328628\n",
      "Fold 12: 0.4776818786831303\n",
      "Fold 13: 0.48515707164017546\n",
      "Fold 14: 0.48944077523551865\n",
      "Fold 15: 0.4904763409769668\n",
      "Fold 16: 0.48620401524031054\n",
      "Fold 17: 0.48620401524031054\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cross_validation_scores)):\n",
    "    print(f'Fold {i+1}: {cross_validation_scores[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settling a CV scheme.\n",
    "cv = ShuffleSplit(n_splits=5, random_state=SEED) #using a shuffle split for CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcuate ROC-AUC for each split\n",
    "#logistic Regression\n",
    "C = 0.001\n",
    "penalty = 'l2'\n",
    "max_iter = 100\n",
    "solver = 'lbfgs'\n",
    "random_state = SEED\n",
    "n_jobs = -1\n",
    "verbose = 0\n",
    "class_weight = 'balanced'\n",
    "\n",
    "final_logit1 = LogisticRegression(C=C,\n",
    "                            penalty=penalty,\n",
    "                            max_iter=max_iter, \n",
    "                            random_state=random_state,\n",
    "                            verbose=verbose,\n",
    "                            n_jobs=n_jobs,\n",
    "                           solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Logit1 test score: 0.5128205128205128\n"
     ]
    }
   ],
   "source": [
    "#final_logit1 = LogisticRegression(C=0.001, random_state=SEED, n_jobs=-1, solver='lbfgs')\n",
    "\n",
    "\n",
    "final_logit1.fit(X_train_full, y_train_full)\n",
    "final_logit1.score(X_test, y_test)\n",
    "print(f'Final Logit1 test score: {final_logit1.score(X_test, y_test)}')\n",
    "#print(f'Final Logit1 test roc_auc score: {roc_auc_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_logit1.predict(X_test)\n",
    "y_pred_proba = final_logit1.predict_proba(X_test)\n",
    "#print(f'Final Logit1 test roc_auc score: {roc_auc_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Logit1 test roc_auc score: 0.5054711246200608\n"
     ]
    }
   ],
   "source": [
    "print(f'Final Logit1 test roc_auc score: {roc_auc_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, final scores from out of the box logistic regression look pretty shit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Model 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train1, X_valid1, X_test1 = X_train.copy(), X_valid.copy(), X_test.copy()\n",
    "\n",
    "X_train_scaled = MinMaxScaler().fit_transform(X_train1)\n",
    "X_valid_scaled = MinMaxScaler().fit_transform(X_valid1)\n",
    "X_test_scaled = MinMaxScaler().fit_transform(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 µs, sys: 1e+03 ns, total: 31 µs\n",
      "Wall time: 36 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://www.kaggle.com/smsrikanthreddy/dota-2-win-prediction-logistic-regression\n",
    "\n",
    "#calcuate ROC-AUC for each split\n",
    "#logistic Regression\n",
    "#logit_params \n",
    "C = 0.001\n",
    "penalty = 'l2'\n",
    "max_iter = 100\n",
    "solver = 'lbfgs'\n",
    "random_state = SEED\n",
    "n_jobs = -1\n",
    "verbose = 0\n",
    "\n",
    "\n",
    "logit2 = LogisticRegression(C=C,\n",
    "                            penalty=penalty,\n",
    "                            max_iter=max_iter, \n",
    "                            random_state=random_state,\n",
    "                            verbose=verbose,\n",
    "                            n_jobs=n_jobs,\n",
    "                           solver=solver)\n",
    "\n",
    "#cv_scores_lr1 = cross_val_score(clf_lr_1, X_train, y, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train Set: 0.5358851674641149\n",
      "Accuracy Score on validation Set: 0.5333333333333333\n",
      "Log Regression validation roc_auc score: 0.4660740203193033\n",
      "CPU times: user 66.8 ms, sys: 57 ms, total: 124 ms\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit2.fit(X_train_scaled, y_train)\n",
    "y_pred = logit1.predict(X_valid)\n",
    "y_pred_proba = logit2.predict_proba(X_valid_scaled)\n",
    "\n",
    "print(f\"Accuracy Score on Train Set: {logit2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Accuracy Score on validation Set: {logit2.score(X_valid_scaled, y_valid)}\")\n",
    "\n",
    "print(f'Log Regression validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remainder = X_train_full.copy()\n",
    "y_remainder = y_train_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 2088)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_remainder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remainder_scaled = MinMaxScaler().fit_transform(X_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Logit2 test score: 0.5128205128205128\n"
     ]
    }
   ],
   "source": [
    "final_logit2 = LogisticRegression(C=0.001, random_state=SEED, n_jobs=-1, solver='lbfgs')\n",
    "\n",
    "final_logit2.fit(X_remainder_scaled, y_remainder)\n",
    "final_logit2.score(X_test_scaled, y_test)\n",
    "print(f'Final Logit2 test score: {final_logit1.score(X_test_scaled, y_test)}')\n",
    "#print(f'Final Logit2 test roc_auc score: {roc_auc_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Logit1 test roc_auc score: 0.5054711246200608\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_logit2.predict(X_test_scaled)\n",
    "y_pred_proba = final_logit2.predict_proba(X_test_scaled)\n",
    "print(f'Final Logit1 test roc_auc score: {roc_auc_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-34aed88147e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "y_prob = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 25],\n",
       "       [32, 22]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-2a1c3b2ec2a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinal_logit2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_logit2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_logit2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coef_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[0;32m--> 263\u001b[0;31m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "final_logit2 = LogisticRegression(C=0.001, random_state=SEED, n_jobs=-1, solver='lbfgs')\n",
    "\n",
    "y_pred = final_logit2.predict(X_test_scaled)\n",
    "y_pred_proba = final_logit2.predict_proba(X_test_scaled)\n",
    "\n",
    "final_logit2.fit(X_remainder_scaled, y_remainder)\n",
    "#final_logit2.score(X_test, y_test)\n",
    "print(f'Final Logit2 test score: {final_logit2.score(X_test_scaled, y_test)}')\n",
    "print(f'Final Logit2 test roc_auc score: {roc_auc_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Logit model cv scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Computing logit cv scores\n",
    "\n",
    "logit_0, cv_scores_0 = logit_cv(X_train, y_train, cv=skf, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_0\n",
    "print(f\"Accuracy Score on Train Set: {logit_0.score(X_train, y_train)}\")\n",
    "print(f\"Predict Probability on Train Set: {logit_0.score(X_train, y_train)}\")\n",
    "print(f'Log Regression validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize what we're working with. The data has been hot encoded (pd.dummy) and scaled (minmax). After that, we performed another split on the training data to create a validation set for the purpose of hyperparameter tuning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search 1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source: https://www.kaggle.com/kuzand/bag-of-heroes-logistic-regression#notebook-container\n",
    "\n",
    "def logit_cv(X_train, y_train, cv=5, random_state=SEED):\n",
    "    \n",
    "    logit = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "\n",
    "    c_values = np.logspace(-2, 1, 20)\n",
    "\n",
    "    logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "                                       scoring='roc_auc',return_train_score=True, cv=cv,\n",
    "                                       n_jobs=-1, verbose=0)\n",
    "\n",
    "    logit_grid_searcher.fit(X_train, y_train)\n",
    "    \n",
    "    cv_scores = []\n",
    "    for i in range(logit_grid_searcher.n_splits_):\n",
    "        cv_scores.append(logit_grid_searcher.cv_results_[f'split{i}_test_score'][logit_grid_searcher.best_index_])\n",
    "    print(f'CV scores: {cv_scores}\\n')\n",
    "    print(f'Mean: {np.mean(cv_scores)}, std: {np.std(cv_scores)}\\n')\n",
    "    \n",
    "    return logit_grid_searcher.best_estimator_, np.array(cv_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit = logit_cv(X_train, y_train, cv=skf, random_state=SEED)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Logit model cv scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Computing logit cv scores\n",
    "\n",
    "logit_0, cv_scores_0 = logit_cv(X_train, y_train, cv=skf, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_0\n",
    "print(f\"Accuracy Score on Train Set: {logit_0.score(X_train, y_train)}\")\n",
    "print(f\"Predict Probability on Train Set: {logit_0.score(X_train, y_train)}\")\n",
    "print(f'Log Regression validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0230f1466a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy Score on Train Set: {logit.score(X_train, y_train)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logit' is not defined"
     ]
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_valid)\n",
    "y_pred_proba = logit.predict_proba(X_valid)\n",
    "\n",
    "print(f\"Accuracy Score on Train Set: {logit.score(X_train, y_train)}\")\n",
    "print(f\"Predict Probability on Train Set: {logit.score(X_train, y_train)}\")\n",
    "print(f\"Accuracy Score on validation Set: {logit.score(X_valid, y_valid)}\")\n",
    "print(f'Log Regression validation roc_auc score: {roc_auc_score(y_pred, y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)\n",
    "\n",
    "logit_pred = logit.predict_proba(X_valid)\n",
    "\n",
    "write_to_submission_file(logit_pred, filename='logit_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaaecb962eeae24e7a8f136b43980c7dc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
